{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Computer Vision Using Transfer Learning Method\n",
    "> AHSNCCU/NTNU CSIE 王修佑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 個人化狗門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以`presidential_doggy_door`資料夾中\"第一狗狗Bo\"為目標建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"presidential_doggy_door/train/bo/bo_10.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 現況：  \n",
    "Dataset小>>>model會Overfitting或Generalization能力差\n",
    "\n",
    "+ Solution:  \n",
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載預先訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 運用[ImageNet 預先訓練模型](https://keras.io/api/applications/vgg/#vgg16-function)\n",
    "+ Task: 改變最後一個Dense Layer，設定旗標 `include_top=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 凍結基本模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新增模型層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 新增新的可訓練層\n",
    "    + Pooling Layer\n",
    "    + Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "# Separately from setting trainable on the model, we set training to False \n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看新的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編寫模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [二元交叉熵](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
    "\n",
    "+ `from_logits=True`: [損失函數](https://gombru.github.io/2018/05/23/cross_entropy_loss/)輸出值不需要被正規化 (例如透過 softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增強資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 Keras 的 [`flow_from_directory`](https://keras.io/api/preprocessing/image/)載入影像\n",
    "\n",
    "[flow_from_directory](https://keras.io/api/preprocessing/image/) 可以調整影像大小來符合模型：244x244 像素和 3 個色頻。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('presidential_doggy_door/train/', \n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode='binary', \n",
    "                                       batch_size=8)\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen.flow_from_directory('presidential_doggy_door/valid/', \n",
    "                                      target_size=(224, 224), \n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode='binary', \n",
    "                                      batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定 `steps_per_epoch`的數量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微調模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在模型的新層經過訓練後，我們可以選擇應用最後一項技巧來改善模型，也就是[微調](https://developers.google.com/machine-learning/glossary#f)。微調時我們要先取消凍結整個模型，並採用非常小的[學習率](https://developers.google.com/machine-learning/glossary#learning-rate)再次訓練模型。這樣一來，預先訓練的基本層會有非常微量的進步並經過稍微調整，以小幅度的方式改善模型。\n",
    "\n",
    "請注意，有凍結層的模型一定要經過完整訓練後，才執行此步驟。我們先前新增至模型的未經訓練池化層和分類層，都是經過隨機初始化。這表示這兩層需要大幅更新才能正確分類影像。在整個[反向傳播](https://developers.google.com/machine-learning/glossary#backpropagation)過程中，最後一層的大型初始更新會導致預先訓練層也需要大幅更新。這些更新可能會破壞預先訓練的重要功能。然而，在最後兩層經過訓練且聚合的情況下，對整體模型的任何更新都會小得多 (尤其是非常小的學習率)，而不會破壞前幾層的功能。\n",
    "\n",
    "讓我們試著取消凍結預先訓練的模型層，然後微調模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# It's important to recompile your model after you make any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are taken into account\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢查預測結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們的模型已經過完整訓練，可以為 Bo 建立狗門了！首先我們來看看模型的預測。我們要用和上次建立狗門相同的方式來預先處理影像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def make_predictions(image_path):\n",
    "    show_image(image_path)\n",
    "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,224,224,3)\n",
    "    image = preprocess_input(image)\n",
    "    preds = model.predict(image)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用幾張影像試試看，然後看看預測結果如何："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('presidential_doggy_door/valid/bo/bo_20.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('presidential_doggy_door/valid/not_bo/121.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看來負數預測結果表示是 Bo，而正數預測結果則表示是其他寵物。我們可以用這項資訊來控制狗門只讓 Bo 進來！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：Bo 的狗門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請填入下列程式碼以實作 Bo 的狗門："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presidential_doggy_door(image_path):\n",
    "    preds = make_predictions(image_path)\n",
    "    if FIXME:\n",
    "        print(\"It's Bo! Let him in!\")\n",
    "    else:\n",
    "        print(\"That's not Bo! Stay out!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」來查看解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "def presidential_doggy_door(image_path):\n",
    "    preds = make_predictions(image_path)\n",
    "    if preds[0] < 0:\n",
    "        print(\"It's Bo! Let him in!\")\n",
    "    else:\n",
    "        print(\"That's not Bo! Stay out!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來試試看吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_doggy_door('presidential_doggy_door/valid/not_bo/131.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_doggy_door('presidential_doggy_door/valid/bo/bo_29.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做得好！透過遷移學習，你使用非常小的資料集就打造出高度準確的模型。這可以是極為強大的技術，也能決定一項專案是成功還是無法實現。我們希望這些技術能在未來的類似案例中幫助到你！\n",
    "\n",
    "在 [NVIDIA 遷移學習工具組](https://developer.nvidia.com/tlt-getting-started)中有豐富的遷移學習相關實用資源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清除記憶體\n",
    "在繼續之前，請執行下列儲存格以清除 GPU 記憶體。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前為止，此實作坊的重點主要是影像分類。在下一節中，為了更全面地介紹深度學習，我們要切換主題並討論與序列資料相關的作業，這需要用到不同的方法。\n",
    "\n",
    "請繼續前往下一節：[*序列資料*](./06_headline_generator.ipynb)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
